{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os, numpy as np, tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import sys\n",
        "from os import path\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "eY0mDa15xPJx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_BY8zddVwT0K"
      },
      "outputs": [],
      "source": [
        "# Import file into colab path\n",
        "\n",
        "if path.exists('full_file.py'):\n",
        "  pass\n",
        "else:\n",
        "  for root, dirs, files in os.walk('PythonFiles'):\n",
        "    with open(\"full_file.py\", \"w\") as new_created_file:\n",
        "      for f in files:\n",
        "        with open('PythonFiles/'+f) as file:\n",
        "          for line in file:\n",
        "              new_created_file.write(line)\n",
        "              \n",
        "          new_created_file.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load python file that we create previouse step and covert to lowercase\n",
        "filename = \"full_file.py\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "metadata": {
        "id": "hDdhVyNYxg-U"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(':: Sample Code Extract ::')\n",
        "print(\"=\"*25)\n",
        "print(raw_text[1000:1500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6slSY_K7Xzm",
        "outputId": "a0bb9cfe-b32a-4728-b276-94334fb4bd55"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ":: Sample Code Extract ::\n",
            "=========================\n",
            "ict the response\n",
            "pred = knn.predict(x_test)\n",
            "\n",
            "# evaluate accuracy\n",
            "print(\"accuracy: {}\".format(accuracy_score(y_test, pred)))\n",
            "\n",
            "# creating odd list of k for knn\n",
            "neighbors = list(range(1, 50, 2))\n",
            "\n",
            "# empty list that will hold cv scores\n",
            "cv_scores = []\n",
            "crossvalidation = kfold(n_splits=10, shuffle=true, random_state=1)\n",
            "# perform 10-fold cross validation\n",
            "for k in neighbors:\n",
            "    knn = kneighborsclassifier(n_neighbors=k)\n",
            "    scores = cross_val_score(knn, x_train, y_train, cv=crossvalidation, scoring='accur\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "# Convert characters to numeric (computer-readable form) > One Hot Encoding or Word Embedding\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "# Convert numeric to categorical for showing prediction\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "QNq08ksAzVKn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the loaded data\n",
        "# length of inputs\n",
        "n_chars = len(raw_text) \n",
        "# number of unique characters\n",
        "n_vocab = len(chars)\n",
        "\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)\n",
        "# set of characters\n",
        "print(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ViM1Vuszar_",
        "outputId": "66ea2770-8eb7-4ba2-b1a8-58a654f796a1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  693045\n",
            "Total Vocab:  80\n",
            "['\\t', '\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '°', '²', '×', 'å', 'ï', '’', '“', '”', '…']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "# define the sequence length(length of input characters as integers)\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "# Convert computer-readable form\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        " seq_in = raw_text[i:i + seq_length]\n",
        " seq_out = raw_text[i + seq_length]\n",
        " # input sequence of data\n",
        " dataX.append([char_to_int[char] for char in seq_in])\n",
        " #  our output\n",
        " dataY.append(char_to_int[seq_out])\n",
        "\n",
        "# number of patterns\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J352DtWwzdEy",
        "outputId": "efad678e-b65f-4893-c3fe-78fda17bd553"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns:  692945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "# for fedding to the neural network\n",
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# X.shape\n",
        "# X[:10]\n",
        "\n",
        "# apply one hot encoder to our output variable\n",
        "y = to_categorical(dataY)\n",
        "# y.shape\n",
        "# dataY[:10]\n",
        "# y[:10]"
      ],
      "metadata": {
        "id": "aycT_ppb0QC-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implement LSTM model\n",
        "# 3 Layer model with dropout to prevent overfitting\n",
        "model = Sequential()\n",
        "# initialized with 256 units of memory, return sequences of data rather than randomly scattered data\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "# output layer generate a probability about what next character \n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "# fit our model with generated input and output\n",
        "model.fit(X, y, epochs=15, batch_size=64, callbacks=callbacks_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmPTQuw80QHm",
        "outputId": "d4c48888-469c-423d-b0e2-6d7bbaf42f00"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "10827/10828 [============================>.] - ETA: 0s - loss: 2.7482\n",
            "Epoch 1: loss improved from inf to 2.74823, saving model to weights-improvement-01-2.7482.hdf5\n",
            "10828/10828 [==============================] - 216s 20ms/step - loss: 2.7482\n",
            "Epoch 2/15\n",
            "10826/10828 [============================>.] - ETA: 0s - loss: 2.2783\n",
            "Epoch 2: loss improved from 2.74823 to 2.27833, saving model to weights-improvement-02-2.2783.hdf5\n",
            "10828/10828 [==============================] - 212s 20ms/step - loss: 2.2783\n",
            "Epoch 3/15\n",
            "10828/10828 [==============================] - ETA: 0s - loss: 2.0547\n",
            "Epoch 3: loss improved from 2.27833 to 2.05469, saving model to weights-improvement-03-2.0547.hdf5\n",
            "10828/10828 [==============================] - 212s 20ms/step - loss: 2.0547\n",
            "Epoch 4/15\n",
            "10828/10828 [==============================] - ETA: 0s - loss: 1.9116\n",
            "Epoch 4: loss improved from 2.05469 to 1.91165, saving model to weights-improvement-04-1.9116.hdf5\n",
            "10828/10828 [==============================] - 211s 20ms/step - loss: 1.9116\n",
            "Epoch 5/15\n",
            "10828/10828 [==============================] - ETA: 0s - loss: 1.8106\n",
            "Epoch 5: loss improved from 1.91165 to 1.81060, saving model to weights-improvement-05-1.8106.hdf5\n",
            "10828/10828 [==============================] - 211s 19ms/step - loss: 1.8106\n",
            "Epoch 6/15\n",
            "10827/10828 [============================>.] - ETA: 0s - loss: 1.7409\n",
            "Epoch 6: loss improved from 1.81060 to 1.74087, saving model to weights-improvement-06-1.7409.hdf5\n",
            "10828/10828 [==============================] - 211s 19ms/step - loss: 1.7409\n",
            "Epoch 7/15\n",
            "10827/10828 [============================>.] - ETA: 0s - loss: 1.6755\n",
            "Epoch 7: loss improved from 1.74087 to 1.67550, saving model to weights-improvement-07-1.6755.hdf5\n",
            "10828/10828 [==============================] - 211s 20ms/step - loss: 1.6755\n",
            "Epoch 8/15\n",
            "10827/10828 [============================>.] - ETA: 0s - loss: 1.6292\n",
            "Epoch 8: loss improved from 1.67550 to 1.62918, saving model to weights-improvement-08-1.6292.hdf5\n",
            "10828/10828 [==============================] - 211s 19ms/step - loss: 1.6292\n",
            "Epoch 9/15\n",
            "10828/10828 [==============================] - ETA: 0s - loss: 1.5911\n",
            "Epoch 9: loss improved from 1.62918 to 1.59108, saving model to weights-improvement-09-1.5911.hdf5\n",
            "10828/10828 [==============================] - 210s 19ms/step - loss: 1.5911\n",
            "Epoch 10/15\n",
            "10827/10828 [============================>.] - ETA: 0s - loss: 1.5566\n",
            "Epoch 10: loss improved from 1.59108 to 1.55663, saving model to weights-improvement-10-1.5566.hdf5\n",
            "10828/10828 [==============================] - 211s 19ms/step - loss: 1.5566\n",
            "Epoch 11/15\n",
            "10826/10828 [============================>.] - ETA: 0s - loss: 1.5295\n",
            "Epoch 11: loss improved from 1.55663 to 1.52955, saving model to weights-improvement-11-1.5295.hdf5\n",
            "10828/10828 [==============================] - 210s 19ms/step - loss: 1.5295\n",
            "Epoch 12/15\n",
            "10827/10828 [============================>.] - ETA: 0s - loss: 1.5063\n",
            "Epoch 12: loss improved from 1.52955 to 1.50627, saving model to weights-improvement-12-1.5063.hdf5\n",
            "10828/10828 [==============================] - 210s 19ms/step - loss: 1.5063\n",
            "Epoch 13/15\n",
            "10826/10828 [============================>.] - ETA: 0s - loss: 1.4837\n",
            "Epoch 13: loss improved from 1.50627 to 1.48371, saving model to weights-improvement-13-1.4837.hdf5\n",
            "10828/10828 [==============================] - 211s 19ms/step - loss: 1.4837\n",
            "Epoch 14/15\n",
            "10827/10828 [============================>.] - ETA: 0s - loss: 1.4671\n",
            "Epoch 14: loss improved from 1.48371 to 1.46712, saving model to weights-improvement-14-1.4671.hdf5\n",
            "10828/10828 [==============================] - 210s 19ms/step - loss: 1.4671\n",
            "Epoch 15/15\n",
            "10827/10828 [============================>.] - ETA: 0s - loss: 1.4471\n",
            "Epoch 15: loss improved from 1.46712 to 1.44713, saving model to weights-improvement-15-1.4471.hdf5\n",
            "10828/10828 [==============================] - 211s 19ms/step - loss: 1.4471\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3c545951f0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the network weights\n",
        "filename = \"weights-improvement-15-1.4471.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# pick a random seed to generate a sequence of character from\n",
        "start = np.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Original Query:\")\n",
        "print(\"=\"*15)\n",
        "# convert the output of the model from numbers to characters\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "print(\"*\"*50)\n",
        "\n",
        "# predict the characters\n",
        "# involve converting the output numbers into characters and then append them to the pattern\n",
        "print(\"\\nPredicted Query:\")\n",
        "print(\"=\"*15)\n",
        "for i in range(5000):\n",
        " x = np.reshape(pattern, (1, len(pattern), 1))\n",
        " x = x / float(n_vocab)\n",
        " prediction = model.predict(x, verbose=0)\n",
        " index = np.argmax(prediction)\n",
        " result = int_to_char[index]\n",
        " seq_in = [int_to_char[value] for value in pattern]\n",
        " print(result, end='')\n",
        "#  sys.stdout.write(result)\n",
        " pattern.append(index)\n",
        " pattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjoHrbdT0QKN",
        "outputId": "833438c2-a5b1-4543-8a8f-331a6d8bb118"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Query:\n",
            "===============\n",
            "\" ain.mean()}')\n",
            "print(f'test data scores saga : {lr2_test} mean: {lr2_test.mean()}')\n",
            "\n",
            "lr1_pred1 = lr1_ \"\n",
            "**************************************************\n",
            "\n",
            "Predicted Query:\n",
            "===============\n",
            "clf_nestor.predict([some_digit3])\n",
            "print('\\n >> conf_sieels of cress in the coass iatr and the tertes tett acta the seruer corneet \"\"\"\n",
            "\n",
            "# - - mark # use the doass doassifier and the coass iath and the doame of the sesuert \n",
            "\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lV8-NZqR0JhZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}